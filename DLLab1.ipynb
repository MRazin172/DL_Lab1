{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOKrLR3Asmz97C+fUgWyG5m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MRazin172/DL_Lab1/blob/main/DLLab1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "eznOzIBGstlb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQk6JCLvro40"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class perceptron:\n",
        "    def __init__(self, inp):\n",
        "        self.weights = np.random.rand(inp)\n",
        "        self.bias = np.random.rand()\n",
        "\n",
        "    def activation_function(self, x):\n",
        "        return 1 if x >= 0 else 0\n",
        "\n",
        "    def predict(self, inputs):\n",
        "        weighted_sum = np.dot(inputs, self.weights) + self.bias\n",
        "        return self.activation_function(weighted_sum)\n",
        "\n",
        "    def train(self, training_data, epochs=1000):\n",
        "        for _ in range(epochs):\n",
        "            errors = 0\n",
        "            for input_data, target_output in training_data:\n",
        "                prediction = self.predict(input_data)\n",
        "                error = target_output - prediction\n",
        "                if error != 0:\n",
        "                    errors += 1\n",
        "                    self.weights += error * np.array(input_data)\n",
        "                    self.bias += error\n",
        "            if errors == 0:\n",
        "                break\n",
        "\n",
        "def boolean_and(inputs):\n",
        "    if inputs[0] == 1 and inputs[1] == 1:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def boolean_or(inputs):\n",
        "    if inputs[0] == 1 or inputs[1] == 1:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def boolean_nand(inputs):\n",
        "    if inputs[0] == 1 and inputs[1] == 1:\n",
        "        return 0\n",
        "    else:\n",
        "        return 1\n",
        "\n",
        "def boolean_xor(inputs):\n",
        "    if inputs[0] != inputs[1]:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "and_data = [\n",
        "    ([0, 0], 0),\n",
        "    ([0, 1], 0),\n",
        "    ([1, 0], 0),\n",
        "    ([1, 1], 1)\n",
        "]\n",
        "\n",
        "or_data = [\n",
        "    ([0, 0], 0),\n",
        "    ([0, 1], 1),\n",
        "    ([1, 0], 1),\n",
        "    ([1, 1], 1)\n",
        "]\n",
        "\n",
        "nand_data = [\n",
        "    ([0, 0], 1),\n",
        "    ([0, 1], 1),\n",
        "    ([1, 0], 1),\n",
        "    ([1, 1], 0)\n",
        "]\n",
        "\n",
        "xor_data = [\n",
        "    ([0, 0], 0),\n",
        "    ([0, 1], 1),\n",
        "    ([1, 0], 1),\n",
        "    ([1, 1], 0)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "andd = perceptron(inp=2)\n",
        "orr = perceptron(inp=2)\n",
        "nand = perceptron(inp=2)\n",
        "xor = perceptron(inp=2)\n",
        "\n",
        "print(\"manual weights:\")\n",
        "print(\"and wieghts:\",andd.weights)\n",
        "print(\"or wieghts:\", orr.weights)\n",
        "print(\"nand weights:\",nand.weights)\n",
        "print(\"xor weihts:\", xor.weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZl_KXe5sp6x",
        "outputId": "018eea8f-d058-4dbc-f5ea-0c0472e8892f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "manual weights:\n",
            "and wieghts: [0.14211047 0.28781205]\n",
            "or wieghts: [0.70926614 0.52067037]\n",
            "nand weights: [0.84430381 0.68275146]\n",
            "xor weihts: [0.42690626 0.04551111]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "andd.train(and_data)\n",
        "orr.train(or_data)\n",
        "nand.train(nand_data)\n",
        "xor.train(xor_data)\n",
        "\n",
        "print(\"weights after training are\")\n",
        "print(\"and :\", andd.weights)\n",
        "print(\"or:\", orr.weights)\n",
        "print(\"nand: \",nand.weights)\n",
        "print(\"xor: \", xor.weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prTktpEGsrTu",
        "outputId": "34db23d9-3095-4eec-ab56-940dcc8f8823"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weights after training are\n",
            "and : [2.14211047 1.28781205]\n",
            "or: [0.70926614 0.52067037]\n",
            "nand:  [-2.15569619 -1.31724854]\n",
            "xor:  [-1.57309374  0.04551111]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initially, wen the perceptrons are created, ther weights are set randmly.\n",
        "\n",
        "However, as the perceptrons are trained with examples of inputs and ther corect outputs, the weights graduly change to valus that help the perceptrons make beter predictions. These weights indicate how much importnce each input shuld have in determing the final output."
      ],
      "metadata": {
        "id": "UD5fmufgx2ob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def function(x):\n",
        "    return x**4 - 3*x**3 + 2\n",
        "\n",
        "def derivative(x):\n",
        "    return 4*x**3 - 9*x**2\n",
        "\n",
        "def gradient_descent(learning_rate, initial_x, precision):\n",
        "    x = initial_x\n",
        "    iterations = 0\n",
        "    while True:\n",
        "        gradient = derivative(x)\n",
        "        new_x = x - learning_rate * gradient\n",
        "        if abs(new_x - x) < precision:\n",
        "            break\n",
        "        x = new_x\n",
        "        iterations += 1\n",
        "    return x, iterations\n",
        "\n",
        "learning_rate = 0.01\n",
        "initial_x = 0\n",
        "precision = 0.0001\n",
        "\n",
        "minimum, iterations = gradient_descent(learning_rate, initial_x, precision)\n",
        "print(f\"Global minimum found at x = {minimum}\")\n",
        "print(f\"Number of iterations: {iterations}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iACSuydM1eCF",
        "outputId": "974a2797-889c-4a5f-d720-a4c772be4587"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global minimum found at x = 0\n",
            "Number of iterations: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code's finds the lowst point on a math curve. ( f(x) = x^4 - 3x^3 + 2). The  Gradient Desent follows the curve's slop Along the way, it traks the steps taken.\n",
        "\n",
        "After its search, the code shares its findins: the spot it thinks is the minimum and how many steps it took."
      ],
      "metadata": {
        "id": "LG3mou6GBsrM"
      }
    }
  ]
}